{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# parsing\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# tokenizing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# vectorizing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# similarity score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('job_data.csv')[['Job Description']]\n",
    "df = df.sample(1000, ignore_index=True, random_state=22)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...\n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...\n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...\n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...\n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Job Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to process job listings\n",
    "def clean_text(resumeText):\n",
    "    resumeText = re.sub(r'<[^>]+>', '', resumeText)     # remove html tags\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    resumeText = re.sub(r'(\\w)(?<![A-Z])([A-Z])(?![A-Z])', r'\\1 \\2', resumeText)\n",
    "    resumeText = resumeText.lower() #remove capital letters\n",
    "    words = resumeText.split(' ')\n",
    "    words = [word for word in words if len(word)>1]\n",
    "    resumeText = ' '.join(words)\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ount executive job number 50955730 description spread your wings we are the duck we inspire and are inspired listen and respond empower our people give back to our community and most importantly celebrate every su ess along the way we do it all the aflac way aflac fortune 500 company is an industry leader in voluntary insurance products that pay cash directly to policyholders and one of america best known brands aflac has been recognized by fortune magazine as one of the 100 best companies to work for in america for 20 consecutive years one of the best workplaces for millennials in 2015 the inaugural year of the award and one of america most admired companies for 18 years our business is about being there for people in need so ask yourself are you the duck if so there home and flourishing career for you at aflac the company aflac the location atlanta columbus ga the division communicorp the opportunity ount executive principal duties amp responsibilities provides ongoing sales and service to long term clients articulates and influences clients regarding communicorp marketing solutions value proposition and translates the influence into revenue increases develops strategies to penetrate ounts with the key decision makers grows revenue both organic and new at high rate through development of strategic plans that meet or exceed clients requirements manages sales cycle from prospecting target ounts and contacts to closing and renewing ounts gathers and uses data to inform management of customer activity identifying customer requirements competitive trends and changing environments collaborates and communicates effectively with internal teams to create strategic solutions that promote customer objectives listens to the needs of the market and shares with the product and marketing teams prepares sales forecast reports of open opportunities as directed by management participates in annual sales budget process provides customer service before during and after the order cycle by acting as the company liaison between the customer and all departments within communicorp works closely with management to develop new sales strategies pricing plans and product service recommendations works independently managing assigned customer base expanding and developing ounts conducts sales and ount presentations performs other duties as required qualifications education amp experience bachelor degree and two years of job related work experience acquiring and retaining ounts and selling marketing solutions both traditional and interactive or an equivalent combination of education and experience sales experience with strong preference for background in the printing and printing related services industry preferred experience in outside b2 sales acquiring new or managing existing ounts in printing or related industry preferred job knowledge amp skills strong analytical skills to assess business opportunities and read prospective buyers knowledge of software contract terms and conditions knowledge of the printing industry including appropriate use of conventional and digital print ability to develop the right messages and provide the right deliverables for customers satisfactory comprehension of automated marketing solutions variable data commerce and other emerging electronic solutions strong understanding of end to end marketing solutions strong organizational and sales budget skills ability to produce follow up metrics and reports for customers excellent verbal and written communication skills must be able to thrive as team player must possess outgoing confident personality suitable for prospecting potential ounts from smaller to larger in person and through linked in and other business related networking avenues ability to produce follow up metrics and reports for customers core competencies action oriented customer focus adaptability listening ethics and values integrity and trust functional competencies business acumen composure creativity drive for results interpersonal savvy perseverance negotiating presentation skills written communications the benefits aflac is known for treating our employees exceptionally well as one of the leaders in the insurance industry we re able to offer one of the most comprehensive health benefits packages available in corporate america including free coverage from one of our pioneering insurance products the aflac cancer policy our employees also enjoy host of other benefits including advancement opportunities opportunities for continued education and professional development merit increases and performance bonuses profit sharing 401 stock purchase plans and many more'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean job description and add each to dataframe\n",
    "df['Clean Job Description'] = df['Job Description'].apply(lambda x: clean_text(x))\n",
    "df['Clean Job Description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert resume PDF into string\n",
    "reader = PdfReader(\"resume.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "page = reader.pages[0]\n",
    "pdf_text = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Justin Carville\\nData Scientist\\nAbout Me\\nProfessional Experience\"Every day is a new adventure.\" This philosophy brought\\nme to Japan in 2017, where I have since leveraged my\\nlove of languages to make a living. My experience\\nworking in marketing and business operations got me\\nexcited about coding and data, so I changed gears and\\nam now on a mission to become fluent in this new field.\\nTechnical Skills\\nPython\\nScikit-Learn\\nMachine\\nLearning\\nNLP\\nDeep Learning\\nLanguages\\nEnglish : native\\nJapanese : business\\nSpanish : conversational\\nEducation\\nLe Wagon - Tokyo (2023)\\n#1 ranked bootcamp worldwide\\n9-week intensive data science\\nbootcamp\\nKICL - Kyoto (2017-2019)\\nJapanese language school\\nPassed JLPT N2\\nUniversity of Rhode Island (2010-2013)\\nBachelor of Arts in Spanish, Journalism\\n Graduated Magna Cum LaudeContact Info\\njccarville@gmail.comTokyo, Japan\\nwww.linkedin.com/in/jccarville/\\nhttps://github.com/just1nt1me\\nLink Academy (2019-2023)\\nFreelance Writer, Editor, Translator (2018-2023)\\nVIPKID | ESL Teacher (2017-2019)WeLoveOsaka (link to articles)SNS video content creation for YouTube, Instagram\\nKPI analysis\\n70+ videos, 66,000+ views, 220+ subscribers\\ntranslate (J ➞ E) and edit articles about tourism, gourmet,\\nevents\\nteach online English lessons for children\\n1000+ classroom hoursComputer Vision\\nSQL\\nGoogle Cloud\\nPlatform\\nStreamlit\\nGit/GithubSNS Marketing Specialist\\nLesson schedule optimization, management\\nTroubleshooting and IT support\\navg of 60 lessons booked / weekOperations Support Staff\\nTeach conversation, business, TOEIC, pronunciation\\nlessons\\n95% student feedback rateESL Teacher\\nAtoZ English\\nwrite, edit test content for EIKEN, TOEIC, TEAP\\nGrape Japan (link to articles)\\nwrite, translate articles on Japanese culture, lifestyle,\\ntrends\\nCCRI | Tutor (2016-2017)\\nteach one-on-one lessons in Biology, Anatomy,\\nPhysiology, Math\\nNPR | Copy Editor, Contributor (2015-2016)\\nfield work, interviews, articles, edits for radio and online\\nInterests\\nweightlifting\\nyoga\\nhikingLink to my\\n music hereClick for \\nPortfolio & Projects'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'justin carville data scientist about me professional experience every day is new adventure this philosophy brought me to japan in 2017 where have since leveraged my love of languages to make living my experience working in marketing and business operations got me excited about coding and data so changed gears and am now on mission to become fluent in this new field technical skills python scikit learn machine learning nlp deep learning languages english native japanese business spanish conversational education le wagon tokyo 2023 ranked bootcamp worldwide week intensive data science bootcamp kicl kyoto 2017 2019 japanese language school passed jlpt n2 university of rhode island 2010 2013 bachelor of arts in spanish journalism graduated magna cum laude contact info arville japan www linkedin com in arville link academy 2019 2023 freelance writer editor translator 2018 2023 vipkid esl teacher 2017 2019 we love osaka link to articles sns video content creation for you tube instagram kpi analysis 70 videos 66 000 views 220 subscribers translate and edit articles about tourism gourmet events teach online english lessons for children 1000 classroom hours computer vision sql google cloud platform streamlit git githubsns marketing specialist lesson schedule optimization management troubleshooting and it support avg of 60 lessons booked week operations support staff teach conversation business toeic pronunciation lessons 95 student feedback rateesl teacher ato english write edit test content for eiken toeic teap grape japan link to articles write translate articles on japanese culture lifestyle trends ccri tutor 2016 2017 teach one on one lessons in biology anatomy physiology math npr copy editor contributor 2015 2016 field work interviews articles edits for radio and online interests weightlifting yoga hiking link to my music here click for portfolio projects'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean resume text\n",
    "resume = clean_text(pdf_text)\n",
    "resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton to tokenize text\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(df, column):\n",
    "    for i in range (0, df.shape[0]):\n",
    "        res = df[column][i]\n",
    "        res = res.split()\n",
    "        res = [stemmer.stem(word) for word in res if word not in stopwords.words('english') and word not in string.punctuation]\n",
    "        df[column][i] = ' '.join(res)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>want help peopl feel better want work top rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>job open id 00315276 logist manag open job tit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>morningstar busi develop team seek highli moti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>schult compani seek task forc director sale jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>duke card specialist member duke card team wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Job Description  \\\n",
       "0    <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1    <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2    <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3    <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4    <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "..                                                 ...   \n",
       "995  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "996  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "997  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "998  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "999  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                                 Clean Job Description  \n",
       "0    ount execut job number 50955730 descript sprea...  \n",
       "1    primari purpos work part product manag team en...  \n",
       "2    descript hire enterpris sale develop repres re...  \n",
       "3    vice presid ad sale market nbc olymp respons w...  \n",
       "4    gener summari senior compens analyst key partn...  \n",
       "..                                                 ...  \n",
       "995  want help peopl feel better want work top rate...  \n",
       "996  job open id 00315276 logist manag open job tit...  \n",
       "997  morningstar busi develop team seek highli moti...  \n",
       "998  schult compani seek task forc director sale jo...  \n",
       "999  duke card specialist member duke card team wor...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df, 'Clean Job Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize resume\n",
    "res = resume\n",
    "res = res.split()\n",
    "res = [stemmer.stem(word) for word in res if word not in stopwords.words('english') and word not in string.punctuation]\n",
    "tokenized_resume = ' '.join(res)\n",
    "df['Resume'] = tokenized_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                               Clean Job Description  \\\n",
       "0  ount execut job number 50955730 descript sprea...   \n",
       "1  primari purpos work part product manag team en...   \n",
       "2  descript hire enterpris sale develop repres re...   \n",
       "3  vice presid ad sale market nbc olymp respons w...   \n",
       "4  gener summari senior compens analyst key partn...   \n",
       "\n",
       "                                              Resume  \n",
       "0  justin carvil data scientist profession experi...  \n",
       "1  justin carvil data scientist profession experi...  \n",
       "2  justin carvil data scientist profession experi...  \n",
       "3  justin carvil data scientist profession experi...  \n",
       "4  justin carvil data scientist profession experi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Words in Job Description / Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "      <th>Resume</th>\n",
       "      <th>JD_num_words</th>\n",
       "      <th>Resume_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>458</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>498</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>430</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>351</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                               Clean Job Description  \\\n",
       "0  ount execut job number 50955730 descript sprea...   \n",
       "1  primari purpos work part product manag team en...   \n",
       "2  descript hire enterpris sale develop repres re...   \n",
       "3  vice presid ad sale market nbc olymp respons w...   \n",
       "4  gener summari senior compens analyst key partn...   \n",
       "\n",
       "                                              Resume  JD_num_words  \\\n",
       "0  justin carvil data scientist profession experi...           458   \n",
       "1  justin carvil data scientist profession experi...           590   \n",
       "2  justin carvil data scientist profession experi...           498   \n",
       "3  justin carvil data scientist profession experi...           430   \n",
       "4  justin carvil data scientist profession experi...           351   \n",
       "\n",
       "   Resume_num_words  \n",
       "0               235  \n",
       "1               235  \n",
       "2               235  \n",
       "3               235  \n",
       "4               235  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['JD_num_words'] = df['Clean Job Description'].apply(lambda x: len(x.split(' ')))\n",
    "df['Resume_num_words'] = df['Resume'].apply(lambda x: len(x.split(' ')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Words in Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "      <th>Resume</th>\n",
       "      <th>JD_num_words</th>\n",
       "      <th>Resume_num_words</th>\n",
       "      <th>word_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>458</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>498</td>\n",
       "      <td>235</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>430</td>\n",
       "      <td>235</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>351</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                               Clean Job Description  \\\n",
       "0  ount execut job number 50955730 descript sprea...   \n",
       "1  primari purpos work part product manag team en...   \n",
       "2  descript hire enterpris sale develop repres re...   \n",
       "3  vice presid ad sale market nbc olymp respons w...   \n",
       "4  gener summari senior compens analyst key partn...   \n",
       "\n",
       "                                              Resume  JD_num_words  \\\n",
       "0  justin carvil data scientist profession experi...           458   \n",
       "1  justin carvil data scientist profession experi...           590   \n",
       "2  justin carvil data scientist profession experi...           498   \n",
       "3  justin carvil data scientist profession experi...           430   \n",
       "4  justin carvil data scientist profession experi...           351   \n",
       "\n",
       "   Resume_num_words  word_common  \n",
       "0               235         19.0  \n",
       "1               235         25.0  \n",
       "2               235         33.0  \n",
       "3               235         14.0  \n",
       "4               235         19.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalized_words_common(row):\n",
    "    jd = set(map(lambda word: word.lower().strip(),row['Clean Job Description'].split(' ')))\n",
    "    rez = set(map(lambda word: word.lower().strip(),row['Resume'].split(' ')))\n",
    "    return 1.0 * len(jd & rez)\n",
    "df['word_common'] = df.apply(normalized_words_common,axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Words in Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "      <th>Resume</th>\n",
       "      <th>JD_num_words</th>\n",
       "      <th>Resume_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>458</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "      <td>446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>25.0</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>498</td>\n",
       "      <td>235</td>\n",
       "      <td>33.0</td>\n",
       "      <td>469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>430</td>\n",
       "      <td>235</td>\n",
       "      <td>14.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>351</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                               Clean Job Description  \\\n",
       "0  ount execut job number 50955730 descript sprea...   \n",
       "1  primari purpos work part product manag team en...   \n",
       "2  descript hire enterpris sale develop repres re...   \n",
       "3  vice presid ad sale market nbc olymp respons w...   \n",
       "4  gener summari senior compens analyst key partn...   \n",
       "\n",
       "                                              Resume  JD_num_words  \\\n",
       "0  justin carvil data scientist profession experi...           458   \n",
       "1  justin carvil data scientist profession experi...           590   \n",
       "2  justin carvil data scientist profession experi...           498   \n",
       "3  justin carvil data scientist profession experi...           430   \n",
       "4  justin carvil data scientist profession experi...           351   \n",
       "\n",
       "   Resume_num_words  word_common  word_total  \n",
       "0               235         19.0       446.0  \n",
       "1               235         25.0       537.0  \n",
       "2               235         33.0       469.0  \n",
       "3               235         14.0       437.0  \n",
       "4               235         19.0       388.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalized_words_total(row):\n",
    "    jd = set(map(lambda word: word.lower().strip(),row['Clean Job Description'].split(' ')))\n",
    "    rez = set(map(lambda word: word.lower().strip(),row['Resume'].split(' ')))\n",
    "    return 1.0 * (len(jd) + len(rez))\n",
    "df['word_total'] = df.apply(normalized_words_total,axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of Shared Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Clean Job Description</th>\n",
       "      <th>Resume</th>\n",
       "      <th>JD_num_words</th>\n",
       "      <th>Resume_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>ount execut job number 50955730 descript sprea...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>458</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.042601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>primari purpos work part product manag team en...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>25.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>0.046555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>descript hire enterpris sale develop repres re...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>498</td>\n",
       "      <td>235</td>\n",
       "      <td>33.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>0.070362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>vice presid ad sale market nbc olymp respons w...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>430</td>\n",
       "      <td>235</td>\n",
       "      <td>14.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>0.032037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>gener summari senior compens analyst key partn...</td>\n",
       "      <td>justin carvil data scientist profession experi...</td>\n",
       "      <td>351</td>\n",
       "      <td>235</td>\n",
       "      <td>19.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.048969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...   \n",
       "\n",
       "                               Clean Job Description  \\\n",
       "0  ount execut job number 50955730 descript sprea...   \n",
       "1  primari purpos work part product manag team en...   \n",
       "2  descript hire enterpris sale develop repres re...   \n",
       "3  vice presid ad sale market nbc olymp respons w...   \n",
       "4  gener summari senior compens analyst key partn...   \n",
       "\n",
       "                                              Resume  JD_num_words  \\\n",
       "0  justin carvil data scientist profession experi...           458   \n",
       "1  justin carvil data scientist profession experi...           590   \n",
       "2  justin carvil data scientist profession experi...           498   \n",
       "3  justin carvil data scientist profession experi...           430   \n",
       "4  justin carvil data scientist profession experi...           351   \n",
       "\n",
       "   Resume_num_words  word_common  word_total  word_share  \n",
       "0               235         19.0       446.0    0.042601  \n",
       "1               235         25.0       537.0    0.046555  \n",
       "2               235         33.0       469.0    0.070362  \n",
       "3               235         14.0       437.0    0.032037  \n",
       "4               235         19.0       388.0    0.048969  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalized_words_share(row):\n",
    "    jd = set(map(lambda word: word.lower().strip(),row['Clean Job Description'].split(' ')))\n",
    "    rez = set(map(lambda word: word.lower().strip(),row['Resume'].split(' ')))\n",
    "    return 1.0 * len(jd & rez)/(len(jd) + len(rez))\n",
    "df['word_share'] = df.apply(normalized_words_share,axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Wuzzy ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Vectorizing jd\n",
      "Vectorizing resume\n"
     ]
    }
   ],
   "source": [
    "# Initialize vectorizer\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "\n",
    "jd_text = list(list(df['Clean Job Description']))\n",
    "resume_text = list(df['Resume'])\n",
    "\n",
    "# Fit the vectorizer\n",
    "print('Fitting')\n",
    "vectorizer1.fit(jd_text)\n",
    "vectorizer2.fit(resume_text)\n",
    "\n",
    "print('Vectorizing jd')\n",
    "jd_vecs_tfidf = vectorizer1.transform(df['Clean Job Description'].values)\n",
    "\n",
    "print('Vectorizing resume')\n",
    "resume_vecs_tfidf = vectorizer2.transform(df['Resume'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 9809), (1000, 175))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_vecs_tfidf.shape, resume_vecs_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE embeddings to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.10.0)\n",
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jccarville/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 15:34:41.916582: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 15:34:42.565187: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-16 15:34:42.717907: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-16 15:34:42.717940: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-16 15:34:42.835214: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-16 15:34:44.845980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-16 15:34:44.846721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-16 15:34:44.846734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m use_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/module_v2.py:93\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a string, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m handle)\n\u001b[0;32m---> 93\u001b[0m module_path \u001b[38;5;241m=\u001b[39m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m is_hub_module_v1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m     95\u001b[0m     native_module\u001b[38;5;241m.\u001b[39mget_module_proto_path(module_path))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_hub_module_v1:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/module_v2.py:48\u001b[0m, in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(handle):\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;124;03m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    A string representing the Module path.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/registry.py:49\u001b[0m, in \u001b[0;36mMultiImplRegister.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/compressed_module_resolver.py:67\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m     63\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_urlopen(request)\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m resolver\u001b[38;5;241m.\u001b[39mDownloadManager(handle)\u001b[38;5;241m.\u001b[39mdownload_and_uncompress(\n\u001b[1;32m     65\u001b[0m       response, tmp_dir)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lock_file_timeout_sec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/resolver.py:421\u001b[0m, in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    419\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading TF-Hub Module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, handle)\n\u001b[1;32m    420\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mMakeDirs(tmp_dir)\n\u001b[0;32m--> 421\u001b[0m \u001b[43mdownload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# Write module descriptor to capture information about which module was\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# downloaded by whom and when. The file stored at the same level as a\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# directory in order to keep the content of the 'model_dir' exactly as it\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# module caching protocol and no code in the TF-Hub library reads its\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# content.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m _write_module_descriptor_file(handle, module_dir)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/compressed_module_resolver.py:63\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__.<locals>.download\u001b[0;34m(handle, tmp_dir)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"Fetch a module via HTTP(S), handling redirect and download headers.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m request \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_compressed_format_query(handle))\n\u001b[0;32m---> 63\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_urlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolver\u001b[38;5;241m.\u001b[39mDownloadManager(handle)\u001b[38;5;241m.\u001b[39mdownload_and_uncompress(\n\u001b[1;32m     65\u001b[0m     response, tmp_dir)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow_hub/resolver.py:528\u001b[0m, in \u001b[0;36mHttpResolverBase._call_urlopen\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    526\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(request)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 528\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:557\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    555\u001b[0m     http_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    556\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) \u001b[38;5;241m+\u001b[39m args\n\u001b[0;32m--> 557\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:749\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    746\u001b[0m fp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    747\u001b[0m fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1450\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    832\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.447px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
